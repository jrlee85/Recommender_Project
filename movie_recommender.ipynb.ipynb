{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### The Movie Database 5000 Movie Dataset\n\nIn this content-based filtering project I will build a function to generate movie recommendations based on their similarity to a user's chosen movie. Similarity will be calculated based on text features of each movie as found in the Movie Database 5000 Movie Dataset.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-24T08:16:07.566878Z","iopub.execute_input":"2022-01-24T08:16:07.56735Z","iopub.status.idle":"2022-01-24T08:16:08.626564Z","shell.execute_reply.started":"2022-01-24T08:16:07.567283Z","shell.execute_reply":"2022-01-24T08:16:08.625358Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport ast\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction import text\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:31.127724Z","iopub.execute_input":"2022-01-31T08:13:31.128717Z","iopub.status.idle":"2022-01-31T08:13:32.253913Z","shell.execute_reply.started":"2022-01-31T08:13:31.128584Z","shell.execute_reply":"2022-01-31T08:13:32.252955Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"movies_df = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_movies.csv\")\ncredits_df = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_credits.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:44.536672Z","iopub.execute_input":"2022-01-31T08:13:44.537826Z","iopub.status.idle":"2022-01-31T08:13:45.700605Z","shell.execute_reply.started":"2022-01-31T08:13:44.537783Z","shell.execute_reply":"2022-01-31T08:13:45.699629Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"movies_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:47.034266Z","iopub.execute_input":"2022-01-31T08:13:47.035201Z","iopub.status.idle":"2022-01-31T08:13:47.064535Z","shell.execute_reply.started":"2022-01-31T08:13:47.035149Z","shell.execute_reply":"2022-01-31T08:13:47.063927Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"credits_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:48.065521Z","iopub.execute_input":"2022-01-31T08:13:48.066031Z","iopub.status.idle":"2022-01-31T08:13:48.077740Z","shell.execute_reply.started":"2022-01-31T08:13:48.065989Z","shell.execute_reply":"2022-01-31T08:13:48.077050Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"The first thing to deal with is the json-like columns. These look like they will contain some useful information, but I won't be able to use them in their current format. Let's have a look at some examples.","metadata":{}},{"cell_type":"code","source":"movies_df.loc[0, 'genres']","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:49.894450Z","iopub.execute_input":"2022-01-31T08:13:49.894782Z","iopub.status.idle":"2022-01-31T08:13:49.908435Z","shell.execute_reply.started":"2022-01-31T08:13:49.894749Z","shell.execute_reply":"2022-01-31T08:13:49.907313Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"movies_df.loc[0,'keywords']","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:50.089804Z","iopub.execute_input":"2022-01-31T08:13:50.090498Z","iopub.status.idle":"2022-01-31T08:13:50.098722Z","shell.execute_reply.started":"2022-01-31T08:13:50.090447Z","shell.execute_reply":"2022-01-31T08:13:50.097599Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"movies_df.loc[0,'production_companies']","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:50.300049Z","iopub.execute_input":"2022-01-31T08:13:50.300478Z","iopub.status.idle":"2022-01-31T08:13:50.307622Z","shell.execute_reply.started":"2022-01-31T08:13:50.300444Z","shell.execute_reply":"2022-01-31T08:13:50.306820Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"movies_df.loc[0,'production_countries']","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:50.462842Z","iopub.execute_input":"2022-01-31T08:13:50.463321Z","iopub.status.idle":"2022-01-31T08:13:50.469509Z","shell.execute_reply.started":"2022-01-31T08:13:50.463283Z","shell.execute_reply":"2022-01-31T08:13:50.468949Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"movies_df.loc[0,'spoken_languages']","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:51.745410Z","iopub.execute_input":"2022-01-31T08:13:51.746194Z","iopub.status.idle":"2022-01-31T08:13:51.751812Z","shell.execute_reply.started":"2022-01-31T08:13:51.746155Z","shell.execute_reply":"2022-01-31T08:13:51.751243Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"credits_df.loc[0,'cast']","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:51.864466Z","iopub.execute_input":"2022-01-31T08:13:51.865065Z","iopub.status.idle":"2022-01-31T08:13:51.872736Z","shell.execute_reply.started":"2022-01-31T08:13:51.865013Z","shell.execute_reply":"2022-01-31T08:13:51.871960Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"credits_df.loc[0,'crew']","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:53.411962Z","iopub.execute_input":"2022-01-31T08:13:53.412502Z","iopub.status.idle":"2022-01-31T08:13:53.420078Z","shell.execute_reply.started":"2022-01-31T08:13:53.412454Z","shell.execute_reply":"2022-01-31T08:13:53.419067Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":" All of these features look like they could be useful, with the exception of `spoken_languages`. The actual language of the movie is represented by the `original_language` column. This may well be an important factor in whether a user likes a movie or not, but the fact that another language is spoken at some point during the movie is unlikely to be important.\n \n`Keywords` and `genres` are clearly going to be important for movie recommendations, so I will need to extract the `name` feature from these json-like entries. `Production_companies` and `Production_countries` may also be useful, as users may prefer movies from a certain company, such as Disney movies, or from a specific country. However, I will note that some of the entries have a lot of associated companies and countries. As there is no clear hierarchy to them I will need to use them all, which could ultimately confuse the model.\n\nFinally, `cast` and `crew` look like they may be useful, but likely only some of the entries. Fortunately, the `cast` column appears to be sorted by order of actor/character importance, so I can simply take the five main actors. Similarly, the `crew` column contains each crew member's role, so I can simply extract the director. \n \nAlthough the entries look like json objects, due to the way Pandas reads the data from the CSV file they are actually strings. Therefore we will need to use a trick to extract the pertinent information. I am grateful to Abhishek Jaiswal for the following method method: https://www.analyticsvidhya.com/blog/2021/12/comprehensive-project-on-building-a-movie-recommender-website/\n\nOriginally in this project I used the method without any modifications. However, on generating recommendations for movies similar to 'Toy Story', one of the top recommendations was the film 'Everything You Always Wanted to Know About Sex (But Were Afraid to Ask)', not the first movie I would think of when recommending something to watch to a fan of Toy Story! I realised that this was happening due to the first name of the directory (Woody Allen) and the name of the main character in Toy Story (Woody). By joining first and last names of cast and crew (and production companies) into a single string I was able to avoid these problems.","metadata":{}},{"cell_type":"code","source":"def get_name(col):\n    my_list = []\n    for i in ast.literal_eval(col):\n        my_list.append(i['name'])\n    return my_list\n\ndef get_actors(col):\n    count = 0\n    my_list = []\n    for i in ast.literal_eval(col):\n        if count != 5:\n            name = i['name']                            \n            name = name.replace(\" \",\"\")  # Code edited to create single string from name\n            my_list.append(name)\n            count+=1\n    return my_list\n\ndef get_director(col):\n    my_list = []\n    for i in ast.literal_eval(col):\n        if i['job'] == 'Director':\n            name = i['name']\n            name = name.replace(\" \",\"\")  # Code edited to create single string from name\n            my_list.append(name)\n    return my_list\n\ndef get_company(col):\n    my_list = []\n    for i in ast.literal_eval(col):\n        name = i['name']                            \n        name = name.replace(\" \",\"\")  # Code edited to create single string from name\n        my_list.append(name)\n    return my_list\n\ndef get_country(col):\n    my_list = []\n    for i in ast.literal_eval(col):\n        my_list.append(i[\"iso_3166_1\"])\n    return my_list","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:13:57.789124Z","iopub.execute_input":"2022-01-31T08:13:57.789772Z","iopub.status.idle":"2022-01-31T08:13:57.803158Z","shell.execute_reply.started":"2022-01-31T08:13:57.789715Z","shell.execute_reply":"2022-01-31T08:13:57.802365Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"movies_df.genres = movies_df.genres.apply(get_name)\nmovies_df.keywords = movies_df.keywords.apply(get_name)\nmovies_df.production_countries = movies_df.production_countries.apply(get_country)\nmovies_df.production_companies = movies_df.production_companies.apply(get_company)\ncredits_df.cast = credits_df.cast.apply(get_actors)\ncredits_df.crew = credits_df.crew.apply(get_director)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:14:00.465178Z","iopub.execute_input":"2022-01-31T08:14:00.465673Z","iopub.status.idle":"2022-01-31T08:14:08.550391Z","shell.execute_reply.started":"2022-01-31T08:14:00.465619Z","shell.execute_reply":"2022-01-31T08:14:08.549705Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Now we want to join the two datasets into a single dataframe. First I will check that movies in both datasets are the same","metadata":{}},{"cell_type":"code","source":"set(movies_df.id.unique() == credits_df.movie_id.unique())","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:14:08.552144Z","iopub.execute_input":"2022-01-31T08:14:08.552623Z","iopub.status.idle":"2022-01-31T08:14:08.561860Z","shell.execute_reply.started":"2022-01-31T08:14:08.552578Z","shell.execute_reply":"2022-01-31T08:14:08.561056Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"As the movies are the same in both datasets, we can join the two together without worrying about introducing NAs.","metadata":{}},{"cell_type":"code","source":"credits_df.rename(columns={'movie_id':'id'}, inplace=True)\ncredits_df.drop([\"title\"], inplace=True, axis=1)\nmovies_df = movies_df.merge(credits_df, on='id')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:14:08.563002Z","iopub.execute_input":"2022-01-31T08:14:08.563201Z","iopub.status.idle":"2022-01-31T08:14:08.595129Z","shell.execute_reply.started":"2022-01-31T08:14:08.563176Z","shell.execute_reply":"2022-01-31T08:14:08.594288Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Now I can drop some of the columns that I don't plan to use. As stated, this recommender project will be based on similarity of text. Therefore, I will drop all non-text columns. I will also drop `original_title` and `spoken_language`. The `title` column contains the important information relating to the movie title, and the language information is found in `original_language`, as discussed above. Finally, homepage is unlikely to be helpful for recommendations, so this will also be removed. ","metadata":{}},{"cell_type":"code","source":"movies_df.drop([\"budget\", \"homepage\", \"popularity\", \"original_title\", \"release_date\", \n                \"revenue\", \"runtime\", \"spoken_languages\", \"vote_average\", \"vote_count\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:14:08.597084Z","iopub.execute_input":"2022-01-31T08:14:08.597733Z","iopub.status.idle":"2022-01-31T08:14:08.606786Z","shell.execute_reply.started":"2022-01-31T08:14:08.597676Z","shell.execute_reply":"2022-01-31T08:14:08.606170Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"How about `status`? What are the different options?","metadata":{}},{"cell_type":"code","source":"movies_df.status.unique()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:14:08.607995Z","iopub.execute_input":"2022-01-31T08:14:08.608545Z","iopub.status.idle":"2022-01-31T08:14:08.618378Z","shell.execute_reply.started":"2022-01-31T08:14:08.608501Z","shell.execute_reply":"2022-01-31T08:14:08.617539Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"We can recommend movies that are due to come out (those in post-production), but it doesn't really make sense to recommend movies that are only rumoured. Let's see how there are.","metadata":{}},{"cell_type":"code","source":"movies_df.status.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:14:46.307160Z","iopub.execute_input":"2022-01-31T08:14:46.307440Z","iopub.status.idle":"2022-01-31T08:14:46.316380Z","shell.execute_reply.started":"2022-01-31T08:14:46.307410Z","shell.execute_reply":"2022-01-31T08:14:46.315485Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Only five of the movies in the dataset are 'rumoured' movies, so it is no problem to drop them. I can then drop the `status` column too.","metadata":{}},{"cell_type":"code","source":"movies_df = movies_df.loc[movies_df.status != 'Rumored']\nmovies_df.drop(\"status\", axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:15:26.994122Z","iopub.execute_input":"2022-01-31T08:15:26.994579Z","iopub.status.idle":"2022-01-31T08:15:27.004475Z","shell.execute_reply.started":"2022-01-31T08:15:26.994526Z","shell.execute_reply":"2022-01-31T08:15:27.003421Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Now let's look at some general information on the dataframe.","metadata":{}},{"cell_type":"code","source":"movies_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:15:48.446075Z","iopub.execute_input":"2022-01-31T08:15:48.446835Z","iopub.status.idle":"2022-01-31T08:15:48.470350Z","shell.execute_reply.started":"2022-01-31T08:15:48.446795Z","shell.execute_reply":"2022-01-31T08:15:48.469739Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"The info method shows that there are a large number of missing values in the `tagline` column, plus a small number in 'overview'. I will replace these NAs with a space.","metadata":{}},{"cell_type":"code","source":"movies_df.tagline = movies_df.tagline.fillna(\" \")\nmovies_df.overview = movies_df.overview.fillna(\" \")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:18:23.637768Z","iopub.execute_input":"2022-01-31T08:18:23.638126Z","iopub.status.idle":"2022-01-31T08:18:23.648294Z","shell.execute_reply.started":"2022-01-31T08:18:23.638092Z","shell.execute_reply":"2022-01-31T08:18:23.646969Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"movies_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:18:30.375628Z","iopub.execute_input":"2022-01-31T08:18:30.376178Z","iopub.status.idle":"2022-01-31T08:18:30.398990Z","shell.execute_reply.started":"2022-01-31T08:18:30.376140Z","shell.execute_reply":"2022-01-31T08:18:30.397711Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Looking at the sample of the dataframe above, it is clear that the function used on the `genres`, `keywords`, etc. columns returned lists. For text processing it would be better if these were string, so I will convert them now.","metadata":{}},{"cell_type":"code","source":"def list_to_string(col):\n    string = ' '.join([str(i) for i in col])\n    return string\n\nmovies_df.genres = movies_df.genres.apply(list_to_string)\nmovies_df.keywords = movies_df.keywords.apply(list_to_string)\nmovies_df.production_companies = movies_df.production_companies.apply(list_to_string)\nmovies_df.production_countries = movies_df.production_countries.apply(list_to_string)\nmovies_df.cast = movies_df.cast.apply(list_to_string)\nmovies_df.crew = movies_df.crew.apply(list_to_string)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:19:40.861762Z","iopub.execute_input":"2022-01-31T08:19:40.862109Z","iopub.status.idle":"2022-01-31T08:19:40.925883Z","shell.execute_reply.started":"2022-01-31T08:19:40.862075Z","shell.execute_reply":"2022-01-31T08:19:40.924858Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"movies_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:19:42.172461Z","iopub.execute_input":"2022-01-31T08:19:42.172797Z","iopub.status.idle":"2022-01-31T08:19:42.193241Z","shell.execute_reply.started":"2022-01-31T08:19:42.172761Z","shell.execute_reply":"2022-01-31T08:19:42.192088Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Before I get to the actual recommender phase, let's have a look at some of the most frequently occurring words in each of the columns. This can be done using a Word Cloud.","metadata":{}},{"cell_type":"code","source":"# Create a function that can be reused for each column. First I am going to create\n# my own set of stopwords.\n\nmy_stopwords = text.ENGLISH_STOP_WORDS\n\ndef wc_generator(col):\n    wc_text = \" \".join(word for word in movies_df[col])\n    wc = WordCloud(background_color = \"white\", max_words = 2000, max_font_size = 100, random_state = 3, \n              stopwords = my_stopwords, contour_width = 3).generate(wc_text)\n    fig = plt.figure(figsize = (20, 10))\n    plt.imshow(wc, interpolation = \"bilinear\")\n    plt.axis(\"off\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:38:33.103980Z","iopub.execute_input":"2022-01-31T08:38:33.104290Z","iopub.status.idle":"2022-01-31T08:38:33.111659Z","shell.execute_reply.started":"2022-01-31T08:38:33.104260Z","shell.execute_reply":"2022-01-31T08:38:33.110818Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"wc_generator(\"genres\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:32:09.460672Z","iopub.execute_input":"2022-01-31T08:32:09.461385Z","iopub.status.idle":"2022-01-31T08:32:10.012932Z","shell.execute_reply.started":"2022-01-31T08:32:09.461346Z","shell.execute_reply":"2022-01-31T08:32:10.012257Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"wc_generator(\"keywords\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:32:11.890498Z","iopub.execute_input":"2022-01-31T08:32:11.891212Z","iopub.status.idle":"2022-01-31T08:32:13.170703Z","shell.execute_reply.started":"2022-01-31T08:32:11.891175Z","shell.execute_reply":"2022-01-31T08:32:13.170077Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"wc_generator(\"overview\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:32:15.851468Z","iopub.execute_input":"2022-01-31T08:32:15.851954Z","iopub.status.idle":"2022-01-31T08:32:17.962226Z","shell.execute_reply.started":"2022-01-31T08:32:15.851918Z","shell.execute_reply":"2022-01-31T08:32:17.961478Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"wc_generator(\"tagline\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:32:17.963617Z","iopub.execute_input":"2022-01-31T08:32:17.964045Z","iopub.status.idle":"2022-01-31T08:32:18.853663Z","shell.execute_reply.started":"2022-01-31T08:32:17.964000Z","shell.execute_reply":"2022-01-31T08:32:18.853025Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"wc_generator(\"cast\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:32:18.854854Z","iopub.execute_input":"2022-01-31T08:32:18.855332Z","iopub.status.idle":"2022-01-31T08:32:19.802811Z","shell.execute_reply.started":"2022-01-31T08:32:18.855291Z","shell.execute_reply":"2022-01-31T08:32:19.801961Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"wc_generator(\"crew\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:32:19.804491Z","iopub.execute_input":"2022-01-31T08:32:19.804720Z","iopub.status.idle":"2022-01-31T08:32:20.489682Z","shell.execute_reply.started":"2022-01-31T08:32:19.804686Z","shell.execute_reply":"2022-01-31T08:32:20.488934Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"wc_generator(\"production_countries\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:32:20.491055Z","iopub.execute_input":"2022-01-31T08:32:20.491665Z","iopub.status.idle":"2022-01-31T08:32:20.990546Z","shell.execute_reply.started":"2022-01-31T08:32:20.491622Z","shell.execute_reply":"2022-01-31T08:32:20.986941Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"wc_generator(\"production_companies\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:32:20.992289Z","iopub.execute_input":"2022-01-31T08:32:20.992501Z","iopub.status.idle":"2022-01-31T08:32:21.738496Z","shell.execute_reply.started":"2022-01-31T08:32:20.992474Z","shell.execute_reply":"2022-01-31T08:32:21.737652Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"The word clouds generally look like we would expect. However, two things stand out to me. Firstly, the most frequently occurring keyword is 'based'. This is not going to be helpful when it comes to finding similarities between movies, so I will add it to the stopwords to be removed. Secondly, there is a notable omission from the production countries' word cloud: US. The reason it is missing is because the list of stopwords contains the word 'us'. I am therefore going to add one word to the stopwords and remove another. Because the stopwords list from Scikit learn is actually a frozenset, I will first create a set version, and then add/remove the words.","metadata":{}},{"cell_type":"code","source":"my_stopwords = set(my_stopwords)\nmy_stopwords.add('based')\nmy_stopwords.remove('us')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:38:56.895232Z","iopub.execute_input":"2022-01-31T08:38:56.895505Z","iopub.status.idle":"2022-01-31T08:38:56.899113Z","shell.execute_reply.started":"2022-01-31T08:38:56.895476Z","shell.execute_reply":"2022-01-31T08:38:56.898352Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"wc_generator(\"keywords\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:39:47.198327Z","iopub.execute_input":"2022-01-31T08:39:47.199364Z","iopub.status.idle":"2022-01-31T08:39:48.431418Z","shell.execute_reply.started":"2022-01-31T08:39:47.199303Z","shell.execute_reply":"2022-01-31T08:39:48.430420Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"wc_generator(\"production_countries\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:39:50.569102Z","iopub.execute_input":"2022-01-31T08:39:50.569489Z","iopub.status.idle":"2022-01-31T08:39:51.278755Z","shell.execute_reply.started":"2022-01-31T08:39:50.569407Z","shell.execute_reply":"2022-01-31T08:39:51.277920Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"That looks better.\n\nNow we can combine all of the text columns into a single column which will be used to create our feature vectors. I will create a copy of the original dataframe so that I can come back to it later.","metadata":{}},{"cell_type":"code","source":"text_df = movies_df.copy(deep=True)\n\ntext_df[\"text\"] = text_df.genres+\" \"+text_df.keywords+\" \"+ \\\n                                \" \"+text_df.original_language+\" \"+text_df.overview+ \\\n                                \" \"+text_df.production_companies+\" \"+text_df.production_countries+ \\\n                                \" \"+text_df.tagline+\" \"+text_df.title+\" \"+text_df.cast+ \\\n                                \" \"+text_df.crew\ntext_df.drop(['genres', 'keywords', 'original_language', 'overview',\n       'production_companies', 'production_countries', 'tagline',\n       'cast', 'crew'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:40:52.722920Z","iopub.execute_input":"2022-01-31T08:40:52.723568Z","iopub.status.idle":"2022-01-31T08:40:52.768186Z","shell.execute_reply.started":"2022-01-31T08:40:52.723512Z","shell.execute_reply":"2022-01-31T08:40:52.767158Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"The first approach I will take is to use Term Frequency-Inverse Document Frequency to get a measure of how important each individual word is in the context of the whole set of words (corpus). Scikit-learn's TfidfVectorizer preforms preprocesing on the text, such as converting to lowercase and tokenising each word. I can pass my edited set of stopwords as an argument in order to remove the stopwords I just defined.","metadata":{}},{"cell_type":"code","source":"tfidf_vectorizer= TfidfVectorizer(stop_words=my_stopwords)\ntfidf_matrix = tfidf_vectorizer.fit_transform(text_df.text)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:44:24.176841Z","iopub.execute_input":"2022-01-31T08:44:24.177180Z","iopub.status.idle":"2022-01-31T08:44:24.864217Z","shell.execute_reply.started":"2022-01-31T08:44:24.177147Z","shell.execute_reply":"2022-01-31T08:44:24.863064Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"To measure similarity I will use cosine similarity, a metric frequently used in text classification. Cosine distance measures the angle between vectors, with a small angle indicating that the vectors are similar. Cosine similarity is simply 1 - cosine distance, in order to give a more intuitive understanding of similarity (i.e. 1 = perfectly similar, 0 = no similarity).\n\nFor each movie in the dataset, I will calculate the cosine similarity between it and every other movie.","metadata":{}},{"cell_type":"code","source":"cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:48:11.305482Z","iopub.execute_input":"2022-01-31T08:48:11.305828Z","iopub.status.idle":"2022-01-31T08:48:12.444785Z","shell.execute_reply.started":"2022-01-31T08:48:11.305796Z","shell.execute_reply":"2022-01-31T08:48:12.443903Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"Next, I create a new dataframe consisting of all of the similarities and using the index from the original dataframe.","metadata":{}},{"cell_type":"code","source":"recommendations_df = pd.DataFrame(cosine_sim, columns=text_df.title, index=text_df.title)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:48:49.517347Z","iopub.execute_input":"2022-01-31T08:48:49.517664Z","iopub.status.idle":"2022-01-31T08:48:49.524053Z","shell.execute_reply.started":"2022-01-31T08:48:49.517633Z","shell.execute_reply":"2022-01-31T08:48:49.523315Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"recommendations_df.iloc[0:5, 0:5]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:49:15.259181Z","iopub.execute_input":"2022-01-31T08:49:15.260132Z","iopub.status.idle":"2022-01-31T08:49:15.275271Z","shell.execute_reply.started":"2022-01-31T08:49:15.260083Z","shell.execute_reply":"2022-01-31T08:49:15.274121Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"As you would expect, the diagonal entries all equal to 1, as this is the movies' similarity with itself. The off-diagonal values show the similarities with other movies, which is what we are interested in.\n\nI will now create a function that a user could use to generate as many recommendations as they like, ordered from most to least similar, excluding the original movie entered by the user.","metadata":{}},{"cell_type":"code","source":"def movie_recommender(movie, num_recommendations, database):\n    temp_df = database[movie]\n    temp_df = temp_df.sort_values(axis=0, ascending=False)\n    for item in temp_df.index[1:num_recommendations+1]:\n        print(\"Recommendation: \\033[1m{}\\033[0m \\t Similarity: \\033[1m{:.2%}\\033[0m\".format(item, temp_df[item]))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:50:59.652385Z","iopub.execute_input":"2022-01-31T08:50:59.653152Z","iopub.status.idle":"2022-01-31T08:50:59.658829Z","shell.execute_reply.started":"2022-01-31T08:50:59.653115Z","shell.execute_reply":"2022-01-31T08:50:59.657907Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"movie_recommender('Toy Story', 10, recommendations_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:51:03.545416Z","iopub.execute_input":"2022-01-31T08:51:03.545695Z","iopub.status.idle":"2022-01-31T08:51:03.558079Z","shell.execute_reply.started":"2022-01-31T08:51:03.545665Z","shell.execute_reply":"2022-01-31T08:51:03.557195Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"The above results show that the recommender is working, at least to an extent. The first two movies returned look like solid recommendations, as Toy Story 2 and 3 are undoubtedly similar to Toy Story. Big and The Indian in the Cupboard also seem like acceptable recommendations, as they are both children's movies. Some of the other recommendations seem less suitable, such as The 40 year Old Virgin and Factory Girl. The most concerning recommendations, though, are Child's Play and Child's Play 2, two movies about a murderous doll! Let's have a look at the entries for our two movies.","metadata":{}},{"cell_type":"code","source":"movies_df[(movies_df.title == \"Child's Play\")|(movies_df.title == \"Toy Story\")]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:55:53.155015Z","iopub.execute_input":"2022-01-31T08:55:53.155298Z","iopub.status.idle":"2022-01-31T08:55:53.175965Z","shell.execute_reply.started":"2022-01-31T08:55:53.155267Z","shell.execute_reply":"2022-01-31T08:55:53.175308Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"Looking at the `keywords` column, the word 'toy' stands out. This is likely to be the reason for the similarity.\n\nAnother approach for representing text as vectors is the Bag of Words approach, which is essentially a count of how many times a word appears in the text. These vectors can be created using Scikit learn's CountVectorizer. Perhaps this will give a better result.","metadata":{}},{"cell_type":"code","source":"count_vectorizer= CountVectorizer(stop_words=my_stopwords)\ncount_matrix = count_vectorizer.fit_transform(text_df.text)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:58:14.714982Z","iopub.execute_input":"2022-01-31T08:58:14.716054Z","iopub.status.idle":"2022-01-31T08:58:15.390992Z","shell.execute_reply.started":"2022-01-31T08:58:14.715985Z","shell.execute_reply":"2022-01-31T08:58:15.390314Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"cosine_sim_count = cosine_similarity(count_matrix, count_matrix)\ncount_recommendations_df = pd.DataFrame(cosine_sim_count, columns=text_df.title, index=text_df.title)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:58:15.392731Z","iopub.execute_input":"2022-01-31T08:58:15.393214Z","iopub.status.idle":"2022-01-31T08:58:16.566752Z","shell.execute_reply.started":"2022-01-31T08:58:15.393170Z","shell.execute_reply":"2022-01-31T08:58:16.565804Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"movie_recommender('Toy Story', 10, count_recommendations_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:58:17.379634Z","iopub.execute_input":"2022-01-31T08:58:17.379998Z","iopub.status.idle":"2022-01-31T08:58:17.396360Z","shell.execute_reply.started":"2022-01-31T08:58:17.379958Z","shell.execute_reply":"2022-01-31T08:58:17.395114Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"In fact, the Bag of Words approach has actually suggested a greater similarity between Toy Story and Child's Play than the TF-IDF approach.\n\nOne other thing that we can try to see if our model improves it to use less features. Feature such as the title, production country and production company may actually be confusing the model. I will try again without these features to see if the results change. As we won't be using production country anymore, we can add 'us' back into the stopwords.","metadata":{}},{"cell_type":"code","source":"my_stopwords.add('us')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:01:25.716047Z","iopub.execute_input":"2022-01-31T09:01:25.717575Z","iopub.status.idle":"2022-01-31T09:01:25.723359Z","shell.execute_reply.started":"2022-01-31T09:01:25.717477Z","shell.execute_reply":"2022-01-31T09:01:25.722067Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"smaller_text_df = movies_df.copy(deep=True)\nsmaller_text_df[\"text\"] = smaller_text_df.genres+\" \"+smaller_text_df.keywords+\" \"+ \\\n                                \" \"+smaller_text_df.overview+\" \"+smaller_text_df.tagline \\\n                                +\" \"+smaller_text_df.cast+\" \"+smaller_text_df.crew\nsmaller_text_df.drop(['genres', 'keywords', 'original_language', 'overview',\n       'production_companies', 'production_countries', 'tagline',\n       'cast', 'crew'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:01:28.993972Z","iopub.execute_input":"2022-01-31T09:01:28.994553Z","iopub.status.idle":"2022-01-31T09:01:29.028237Z","shell.execute_reply.started":"2022-01-31T09:01:28.994516Z","shell.execute_reply":"2022-01-31T09:01:29.026864Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"tfidf_vectorizer= TfidfVectorizer(stop_words=my_stopwords)\ntfidf_matrix = tfidf_vectorizer.fit_transform(smaller_text_df.text)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:01:31.447205Z","iopub.execute_input":"2022-01-31T09:01:31.448204Z","iopub.status.idle":"2022-01-31T09:01:32.026706Z","shell.execute_reply.started":"2022-01-31T09:01:31.448152Z","shell.execute_reply":"2022-01-31T09:01:32.025821Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\nrecommendations_df = pd.DataFrame(cosine_sim, columns=smaller_text_df.title, index=smaller_text_df.title)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:01:32.028270Z","iopub.execute_input":"2022-01-31T09:01:32.028532Z","iopub.status.idle":"2022-01-31T09:01:32.992805Z","shell.execute_reply.started":"2022-01-31T09:01:32.028500Z","shell.execute_reply":"2022-01-31T09:01:32.991944Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"movie_recommender('Toy Story', 10, recommendations_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:01:33.922835Z","iopub.execute_input":"2022-01-31T09:01:33.923137Z","iopub.status.idle":"2022-01-31T09:01:33.936184Z","shell.execute_reply.started":"2022-01-31T09:01:33.923103Z","shell.execute_reply":"2022-01-31T09:01:33.935006Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"count_vectorizer= CountVectorizer(stop_words='english')\ncount_matrix = count_vectorizer.fit_transform(smaller_text_df.text)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:01:36.543551Z","iopub.execute_input":"2022-01-31T09:01:36.544032Z","iopub.status.idle":"2022-01-31T09:01:37.141904Z","shell.execute_reply.started":"2022-01-31T09:01:36.543995Z","shell.execute_reply":"2022-01-31T09:01:37.141019Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"cosine_sim_count = cosine_similarity(count_matrix, count_matrix)\ncount_recommendations_df = pd.DataFrame(cosine_sim_count, columns=smaller_text_df.title, index=smaller_text_df.title)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:01:37.368798Z","iopub.execute_input":"2022-01-31T09:01:37.369361Z","iopub.status.idle":"2022-01-31T09:01:38.282484Z","shell.execute_reply.started":"2022-01-31T09:01:37.369311Z","shell.execute_reply":"2022-01-31T09:01:38.281334Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"movie_recommender('Toy Story', 10, count_recommendations_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:01:39.741009Z","iopub.execute_input":"2022-01-31T09:01:39.741950Z","iopub.status.idle":"2022-01-31T09:01:39.757120Z","shell.execute_reply.started":"2022-01-31T09:01:39.741885Z","shell.execute_reply":"2022-01-31T09:01:39.756104Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"This hasn't had much of an effect on the recommender. Let's have a look at a few other recommendations. I will use the TF-IDF model.","metadata":{}},{"cell_type":"code","source":"movie_recommender('Alien', 10, recommendations_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:03:41.403805Z","iopub.execute_input":"2022-01-31T09:03:41.404459Z","iopub.status.idle":"2022-01-31T09:03:41.420657Z","shell.execute_reply.started":"2022-01-31T09:03:41.404395Z","shell.execute_reply":"2022-01-31T09:03:41.419388Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"movie_recommender('Jurassic Park', 10, recommendations_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:04:01.823437Z","iopub.execute_input":"2022-01-31T09:04:01.823907Z","iopub.status.idle":"2022-01-31T09:04:01.839020Z","shell.execute_reply.started":"2022-01-31T09:04:01.823841Z","shell.execute_reply":"2022-01-31T09:04:01.837449Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"movie_recommender('The Godfather', 10, recommendations_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:04:35.328203Z","iopub.execute_input":"2022-01-31T09:04:35.328528Z","iopub.status.idle":"2022-01-31T09:04:35.345698Z","shell.execute_reply.started":"2022-01-31T09:04:35.328496Z","shell.execute_reply":"2022-01-31T09:04:35.344527Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"The results show us the limitations of the recommender. It does seem to be able to pick up on general themes, hence recommending movies set in space for Alien, movies with dinosaurs for Jurassic Park, and movies involving the Mafia for The Godfather. In particular, the top one or two results do appear to be good recommendations. However, beyond this, the recommender seems to give too little weight to the movie genre, for example when faced with The Godfather it gives a higher recommendation to the comedy Micky Blues Eyes than it gives to the much more similar film Goodfellas. It also fails to take into account whether the movie is appropriate for adults or children.\n\nIf i were to expand on this project, I would look to give more weight to genre, as well as adding a feature indicating whether the film was for adults or children.","metadata":{}}]}